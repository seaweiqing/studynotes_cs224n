# studynotes_cs224n
This repository is created for sharing study notes for the nlp class cs224n

<p style=""></p><p><b>【content】</b></p><p><b>prerequisite:&nbsp;</b></p><p>- linear algebra review</p><p>- probability theorem review</p><p>- convex optimization review</p><p></p>
</p>
<p style=""></p><p><b>week 1: word2vec, skip-gram</b></p><p>- lecture 1: class introduction</p><p>- lecture 2: word2vec</p><p>- word2vec tutorial: skip gram neural network architecture for Word2Vec</p><p>- lecture notes01: Natural Language Processing. Word Vectors. Singular Value Decomposition. Skip-gram. Continuous Bag of Words (CBOW). Negative Sampling. Hierarchical Softmax. Word2Vec</p><p>- paper: Distributed Representations ofWords and Phrases and their Compositionality: subsampling, negative sampling, method for finding phrases</p><p>- paper: Efficient Estimation of Word Representations in Vector Space: dealing with large data set, achieving large improvements in accuracy at much lower computational cost</font></p><p></p>
<p style=""></p><p><b><font size="2"><b>week 2: GloVe, word vector evaluation</b></font></p><p><font size="2">- lecture 3: finish word2vec, GloVe intro</font></p><p><font size="2">- lecture notes02: GloVe, evaluation, Window classification</font></p><p><font size="2">- paper: GloVe_Global Vectors for Word Representation</font></p><p><font size="2">- paper: Evaluation methods for unsupervised word embeddings</font></p><p><font size="2">- paper: Improving Distributional Similarity with Lessons Learned from Word Embeddings</font></p><p></p>

<p style=""></p><p><b><font size="2">week 3:&nbsp;</font><span style="font-size: small;">classification,&nbsp;</span><span style="font-size: small;">backward propagation</span></b></p><p><font size="2">- lecture 4: classification</font></p><p><font size="2">- lecture 5: multi-layer NN, backward propagation</font></p><p><font size="2">- lecture notes03: Neural networks. Forward computation. Backward&nbsp;</font><span style="font-size: small;">propagation.&nbsp;</span></p><p><font size="2">- gradient notes: Computing Neural Network Gradients</font></p><p><font size="2">- paper: review-differential-calculus</font></p><p><font size="2">- paper: Natural Language Processing (almost) from Scratch</font></p><p><font size="2">- paper: backprop_old</font></p><div><br></div><p></p>
